ID,URL,Date,Title,InfoTheory,CompVis,Math,Abstract
no-150100335,arxiv.org/abs/1501.00335,1/1/15,A Data Transparency Framework for Mobile Applications,0,0,0," A Data Transparency Framework for Mobile Applications In today's mobile application marketplace, the ability of consumers to make informed choices regarding their privacy is extremely limited. Consumers largely rely on privacy policies and app permission mechanisms, but these do an inadequate job of conveying how information will be collected, used, stored, and shared. Mobile application developers go largely unrewarded for making apps more privacy conscious as it is difficult to communicate these features to consumers while they are searching for a new app. This paper provides an overview of a framework designed to help consumers make informed choices, and an incentive mechanism to encourage app developers to implement it. This framework includes machine readable privacy policies encouraged by mobile app stores and enhanced by user software agents. Such a framework would provide the foundation required for more advanced forms of privacy management to develop. "
no-14024178,arxiv.org/abs/1402.4178,1/1/15,A reclaimer scheduling problem arising in coal stockyard management,0,0,0," A reclaimer scheduling problem arising in coal stockyard management We study a number of variants of an abstract scheduling problem inspired by the scheduling of reclaimers in the stockyard of a coal export terminal. We analyze the complexity of each of the variants, providing complexity proofs for some and polynomial algorithms for others. For one, especially interesting variant, we also develop a constant factor approximation algorithm. "
no-150100263,arxiv.org/abs/1501.00263,1/1/15,Communication-Efficient Distributed Optimization of Self-Concordant Empirical Loss,0,0,1," Communication-Efficient Distributed Optimization of Self-Concordant Empirical Loss We consider distributed convex optimization problems originated from sample average approximation of stochastic optimization, or empirical risk minimization in machine learning. We assume that each machine in the distributed computing system has access to a local empirical loss function, constructed with i.i.d. data sampled from a common distribution. We propose a communication-efficient distributed algorithm to minimize the overall empirical loss, which is the average of the local empirical losses. The algorithm is based on an inexact damped Newton method, where the inexact Newton steps are computed by a distributed preconditioned conjugate gradient method. We analyze its iteration complexity and communication efficiency for minimizing self-concordant empirical loss functions, and discuss the results for distributed ridge regression, logistic regression and binary classification with a smoothed hinge loss. In a standard setting for supervised learning, the required number of communication rounds of the algorithm does not increase with the sample size, and only grows slowly with the number of machines. "
no-150100287,arxiv.org/abs/1501.00287,1/1/15,Consistent Classification Algorithms for Multi-class Non-Decomposable Performance Metrics,0,0,0," Consistent Classification Algorithms for Multi-class Non-Decomposable Performance Metrics We study consistency of learning algorithms for a multi-class performance metric that is a non-decomposable function of the confusion matrix of a classifier and cannot be expressed as a sum of losses on individual data points; examples of such performance metrics include the macro F-measure popular in information retrieval and the G-mean metric used in class-imbalanced problems. While there has been much work in recent years in understanding the consistency properties of learning algorithms for `binary' non-decomposable metrics, little is known either about the form of the optimal classifier for a general multi-class non-decomposable metric, or about how these learning algorithms generalize to the multi-class case. In this paper, we provide a unified framework for analysing a multi-class non-decomposable performance metric, where the problem of finding the optimal classifier for the performance metric is viewed as an optimization problem over the space of all confusion matrices achievable under the given distribution. Using this framework, we show that (under a continuous distribution) the optimal classifier for a multi-class performance metric can be obtained as the solution of a cost-sensitive classification problem, thus generalizing several previous results on specific binary non-decomposable metrics. We then design a consistent learning algorithm for concave multi-class performance metrics that proceeds via a sequence of cost-sensitive classification problems, and can be seen as applying the conditional gradient CG optimization method over the space of feasible confusion matrices. To our knowledge, this is the first efficient learning algorithm (whose running time is polynomial in the number of classes) that is consistent for a large family of multi-class non-decomposable metrics. Our consistency proof uses a novel technique based on the convergence analysis of the CG method. "
no-11070586,arxiv.org/abs/1107.0586,1/1/15,Managing key multicasting through orthogonal systems,0,0,0, Managing key multicasting through orthogonal systems In this paper we propose a new protocol to manage multicast key distribution. The protocol is based on the use of orthogonal systems in vector spaces. The main advantage in comparison to other existing multicast key management protocols is that the length and the number of the messages which have to be sent are considerably smaller. This makes the protocol especially attractive when the number of legitimate receivers is large. 
no-150100305,arxiv.org/abs/1501.00305,1/1/15,Massive MIMO and Waveform Design for 5th Generation Wireless Communication Systems,1,0,1," Massive MIMO and Waveform Design for 5th Generation Wireless Communication Systems This article reviews existing related work and identifies the main challenges in the key 5G area at the intersection of waveform design and large-scale multiple antenna systems, also known as Massive MIMO. The property of self-equalization is introduced for Filter Bank Multicarrier FBMC-based Massive MIMO, which can reduce the number of subcarriers required by the system. It is also shown that the blind channel tracking property of FBMC can be used to address pilot contamination -- one of the main limiting factors of Massive MIMO systems. Our findings shed light into and motivate for an entirely new research line towards a better understanding of waveform design with emphasis on FBMC-based Massive MIMO networks. "
no-150100265,arxiv.org/abs/1501.00265,1/1/15,On the complexity of finite valued functions,0,0,0," On the complexity of finite valued functions The essential variables in a finite function are defined as variables which occur in and weigh with the values of that function. The number of essential variables is an important measure of complexity for discrete functions. When replacing some variables in a function with constants the resulting functions are called subfunctions, and when replacing all essential variables in a function with constants we obtain an implementation of this function. Such an implementation corresponds with a path in an ordered decision diagram ODD of the function which connects the root with a leaf of the diagram. The sets of essential variables in subfunctions of are called separable in . In this paper we study several properties of separable sets of variables in functions which directly impact on the number of implementations and subfunctions in these functions. We define equivalence relations which classify the functions of valued logic into classes with same number of implementations, subfunctions or separable sets. These relations induce three transformation groups which are compared with the lattice of all subgroups of restricted affine group RAG. This allows us to solve several important computational and combinatorial problems. "
no-14128246,arxiv.org/abs/1412.8246,1/1/15,Pattern Matching and Local Alignment for RNA Structures,0,0,0," Pattern Matching and Local Alignment for RNA Structures The primary structure of a ribonucleic acid RNA molecule can be represented as a sequence of nucleotides (bases) over the alphabet {A, C, G, U}. The secondary or tertiary structure of an RNA is a set of base pairs which form bonds between A-U and G-C. For secondary structures, these bonds have been traditionally assumed to be one-to-one and non-crossing. This paper considers pattern matching as well as local alignment between two RNA structures. For pattern matching, we present two algorithms, one for obtaining an exact match, the other for approximate match. We then present an algorithm for RNA local structural alignment. "
no-150100316,arxiv.org/abs/1501.00316,1/1/15,Phenomenological modelling for Time-Resolved Electron Paramagnetic Resonance in radical-triplet system,1,0,1," Phenomenological modelling for Time-Resolved Electron Paramagnetic Resonance in radical-triplet system The spin dynamics of radical-triplet system RTS has been calculated by using the Lindblad formalism within the theory of open quantum system. The single-radical-triplet system SRTS is considered here for single-qubit quantum gate operations while double-radical-triplet system DRTS for two-qubit operations. The environment effects taken into account include the spin-lattice relaxation of the triplet exciton and radical spin-, the inter-system crossing process that induces the transition from singlet excited state to the triplet ground state, and the rather slow relaxation process from the triplet ground state back down to the singlet ground state. These calculations shown that the line shape broadening is strongly related to the exchange interaction between triplet and exciton, which can be understood as a spontaneous magnetic field created by the triplet renormalises the original spin- electron spin resonance spectra. This work will provide key information about the spin dynamics for building optically-controlled molecular quantum gate out of radical-bearing molecules. Moreover, this has generated the further theoretical question on how the mixture of fermion and boson behaves. "
no-14061967,arxiv.org/abs/1406.1967,1/1/15,Quasi-Monte Carlo point sets with small $t$-values and WAFOM,0,0,1," Quasi-Monte Carlo point sets with small values and WAFOM The value of a net is an important criterion of point sets for quasi-Monte Carlo integration, and many point sets are constructed in terms of the values, as this leads to small integration error bounds. Recently, Matsumoto, Saito, and Matoba proposed the Walsh figure of merit WAFOM as a quickly computable criterion of point sets that ensures higher order convergence for function classes of very high smoothness. In this paper, we consider a search algorithm for point sets whose value and WAFOM are both small, so as to be effective for a wider range of function classes. For this, we fix digital nets with small values (e.g., Sobol' or Niederreiter--Xing nets) in advance, apply random linear scrambling, and select scrambled digital nets in terms of WAFOM. Experiments show that the resulting point sets improve the rates of convergence for smooth functions and are robust for non-smooth functions. "
no-13052436,arxiv.org/abs/1305.2436,1/1/15,Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima,1,0,1," Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima We provide novel theoretical results regarding local optima of regularized estimators, allowing for nonconvexity in both loss and penalty functions. Under restricted strong convexity on the loss and suitable regularity conditions on the penalty, we prove that \emph{any stationary point} of the composite objective function will lie within statistical precision of the underlying parameter vector. Our theory covers many nonconvex objective functions of interest, including the corrected Lasso for errors-in-variables linear models; regression for generalized linear models with nonconvex penalties such as SCAD, MCP, and capped-; and high-dimensional graphical model estimation. We quantify statistical accuracy by providing bounds on the , , and prediction error between stationary points and the population-level optimum. We also propose a simple modification of composite gradient descent that may be used to obtain a near-global optimum within statistical precision in steps, which is the fastest possible rate of any first-order method. We provide simulation studies illustrating the sharpness of our theoretical results. "
no-14115065,arxiv.org/abs/1411.5065,1/1/15,SIRF: Simultaneous Image Registration and Fusion in A Unified Framework,0,1,0," SIRF: Simultaneous Image Registration and Fusion in A Unified Framework In this paper, we propose a novel method for image fusion with a high-resolution panchromatic image and a low-resolution multispectral image at the same geographical location. The fusion is formulated as a convex optimization problem which minimizes a linear combination of a least-squares fitting term and a dynamic gradient sparsity regularizer. The former is to preserve accurate spectral information of the multispectral image, while the latter is to keep sharp edges of the high-resolution panchromatic image. We further propose to simultaneously register the two images during the fusing process, which is naturally achieved by virtue of the dynamic gradient sparsity property. An efficient algorithm is then devised to solve the optimization problem, accomplishing a linear computational complexity in the size of the output image in each iteration. We compare our method against seven state-of-the-art image fusion methods on multispectral image datasets from four satellites. Extensive experimental results demonstrate that the proposed method substantially outperforms the others in terms of both spatial and spectral qualities. We also show that our method can provide high-quality products from coarsely registered real-world datasets. Finally, a MATLAB implementation is provided to facilitate future research. "
no-150100255,arxiv.org/abs/1501.00255,1/1/15,Speculative Approximations for Terascale Analytics,0,0,0," Speculative Approximations for Terascale Analytics Model calibration is a major challenge faced by the plethora of statistical analytics packages that are increasingly used in Big Data applications. Identifying the optimal model parameters is a time-consuming process that has to be executed from scratch for every dataset/model combination even by experienced data scientists. We argue that the incapacity to evaluate multiple parameter configurations simultaneously and the lack of support to quickly identify sub-optimal configurations are the principal causes. In this paper, we develop two database-inspired techniques for efficient model calibration. Speculative parameter testing applies advanced parallel multi-query processing methods to evaluate several configurations concurrently. The number of configurations is determined adaptively at runtime, while the configurations themselves are extracted from a distribution that is continuously learned following a Bayesian process. Online aggregation is applied to identify sub-optimal configurations early in the processing by incrementally sampling the training dataset and estimating the objective function corresponding to each configuration. We design concurrent online aggregation estimators and define halting conditions to accurately and timely stop the execution. We apply the proposed techniques to distributed gradient descent optimization -- batch and incremental -- for support vector machines and logistic regression models. We implement the resulting solutions in GLADE PF-OLA -- a state-of-the-art Big Data analytics system -- and evaluate their performance over terascale-size synthetic and real datasets. The results confirm that as many as 32 configurations can be evaluated concurrently almost as fast as one, while sub-optimal configurations are detected accurately in as little as a fraction of the time. "
no-150100312,arxiv.org/abs/1501.00312,1/1/15,Statistical consistency and asymptotic normality for high-dimensional robust M-estimators,1,0,1," Statistical consistency and asymptotic normality for high-dimensional robust M-estimators We study theoretical properties of regularized robust M-estimators, applicable when data are drawn from a sparse high-dimensional linear model and contaminated by heavy-tailed distributions and/or outliers in the additive errors and covariates. We first establish a form of local statistical consistency for the penalized regression estimators under fairly mild conditions on the error distribution: When the derivative of the loss function is bounded and satisfies a local restricted curvature condition, all stationary points within a constant radius of the true regression vector converge at the minimax rate enjoyed by the Lasso with sub-Gaussian errors. When an appropriate nonconvex regularizer is used in place of an l_1-penalty, we show that such stationary points are in fact unique and equal to the local oracle solution with the correct support---hence, results on asymptotic normality in the low-dimensional case carry over immediately to the high-dimensional setting. This has important implications for the efficiency of regularized nonconvex M-estimators when the errors are heavy-tailed. Our analysis of the local curvature of the loss function also has useful consequences for optimization when the robust regression function and/or regularizer is nonconvex and the objective function possesses stationary points outside the local region. We show that as long as a composite gradient descent algorithm is initialized within a constant radius of the true regression vector, successive iterates will converge at a linear rate to a stationary point within the local region. Furthermore, the global optimum of a convex regularized robust regression function may be used to obtain a suitable initialization. The result is a novel two-step procedure that uses a convex M-estimator to achieve consistency and a nonconvex M-estimator to increase efficiency. "
no-14104448,arxiv.org/abs/1410.4448,1/1/15,Stochastic Parity Games on Lossy Channel Systems,0,0,0," Stochastic Parity Games on Lossy Channel Systems We give an algorithm for solving stochastic parity games with almost-sure winning conditions on {\it lossy channel systems}, under the constraint that both players are restricted to finite-memory strategies. First, we describe a general framework, where we consider the class of 2 1/2-player games with almost-sure parity winning conditions on possibly infinite game graphs, assuming that the game contains a {\it finite attractor}. An attractor is a set of states (not necessarily absorbing) that is almost surely re-visited regardless of the players' decisions. We present a scheme that characterizes the set of winning states for each player. Then, we instantiate this scheme to obtain an algorithm for {\it stochastic game lossy channel systems}. "
no-14033991,arxiv.org/abs/1403.3991,1/1/15,Throughput Optimization for Massive MIMO Systems Powered by Wireless Energy Transfer,1,0,1," Throughput Optimization for Massive MIMO Systems Powered by Wireless Energy Transfer This paper studies a wireless-energy-transfer WET enabled massive multiple-input-multiple-output MIMO system MM consisting of a hybrid data-and-energy access point (H-AP) and multiple single-antenna users. In the WET-MM system, the H-AP is equipped with a large number of antennas and functions like a conventional AP in receiving data from users, but additionally supplies wireless power to the users. We consider frame-based transmissions. Each frame is divided into three phases: the uplink channel estimation CE phase, the downlink WET phase, as well as the uplink wireless information transmission WIT phase. Firstly, users use a fraction of the previously harvested energy to send pilots, while the H-AP estimates the uplink channels and obtains the downlink channels by exploiting channel reciprocity. Next, the H-AP utilizes the channel estimates just obtained to transfer wireless energy to all users in the downlink via energy beamforming. Finally, the users use a portion of the harvested energy to send data to the H-AP simultaneously in the uplink (reserving some harvested energy for sending pilots in the next frame). To optimize the throughput and ensure rate fairness, we consider the problem of maximizing the minimum rate among all users. In the large- regime, we obtain the asymptotically optimal solutions and some interesting insights for the optimal design of WET-MM system. We define a metric, namely, the massive MIMO degree-of-rate-gain (MM-DoRG), as the asymptotic UL rate normalized by . We show that the proposed WET-MM system is optimal in terms of MM-DoRG, i.e., it achieves the same MM-DoRG as the case with ideal CE. "
no-150100436,arxiv.org/abs/1501.00436,2/1/15,An Experimental Analysis of the Echo State Network Initialization Using the Particle Swarm Optimization,0,0,0," An Experimental Analysis of the Echo State Network Initialization Using the Particle Swarm Optimization This article introduces a robust hybrid method for solving supervised learning tasks, which uses the Echo State Network ESN model and the Particle Swarm Optimization PSO algorithm. An ESN is a Recurrent Neural Network with the hidden-hidden weights fixed in the learning process. The recurrent part of the network stores the input information in internal states of the network. Another structure forms a free-memory method used as supervised learning tool. The setting procedure for initializing the recurrent structure of the ESN model can impact on the model performance. On the other hand, the PSO has been shown to be a successful technique for finding optimal points in complex spaces. Here, we present an approach to use the PSO for finding some initial hidden-hidden weights of the ESN model. We present empirical results that compare the canonical ESN model with this hybrid method on a wide range of benchmark problems. "
no-14012248,arxiv.org/abs/1401.2248,2/1/15,Boolean Functions  Quantum Gates  Hamilton Operators  Spin Systems and Computer Algebra,0,0,0," Boolean Functions, Quantum Gates, Hamilton Operators, Spin Systems and Computer Algebra We describe the construction of quantum gates (unitary operators) from boolean functions and give a number of applications. Both non-reversible and reversible boolean functions are considered. The construction of the Hamilton operator for a quantum gate is also described with the Hamilton operator expressed as spin system. Computer algebra implementations are provided. "
no-150100387,arxiv.org/abs/1501.00387,2/1/15,Campaign Management under Approval-Driven Voting Rules,0,0,0," Campaign Management under Approval-Driven Voting Rules Approval-like voting rules, such as Sincere-Strategy Preference-Based Approval voting (SP-AV), the Bucklin rule (an adaptive variant of Approval voting), and the Fallback rule (an adaptive variant of SP-AV) have many desirable properties: for example, they are easy to understand and encourage the candidates to choose electoral platforms that have a broad appeal. In this paper, we investigate both classic and parameterized computational complexity of electoral campaign management under such rules. We focus on two methods that can be used to promote a given candidate: asking voters to move this candidate upwards in their preference order or asking them to change the number of candidates they approve of. We show that finding an optimal campaign management strategy of the first type is easy for both Bucklin and Fallback. In contrast, the second method is computationally hard even if the degree to which we need to affect the votes is small. Nevertheless, we identify a large class of scenarios that admit fixed-parameter tractable algorithms. "
no-150100358,arxiv.org/abs/1501.00358,2/1/15,Comprehend DeepWalk as Matrix Factorization,0,0,0," Comprehend DeepWalk as Matrix Factorization Word2vec, as an efficient tool for learning vector representation of words has shown its effectiveness in many natural language processing tasks. Mikolov et al. issued Skip-Gram and Negative Sampling model for developing this toolbox. Perozzi et al. introduced the Skip-Gram model into the study of social network for the first time, and designed an algorithm named DeepWalk for learning node embedding on a graph. We prove that the DeepWalk algorithm is actually factoring a matrix M where each entry M_{ij} is logarithm of the average probability that node i randomly walks to node j in fix steps. "
no-150100386,arxiv.org/abs/1501.00386,2/1/15,Computability on the countable ordinals and the Hausdorff-Kuratowski theorem,0,0,1," Computability on the countable ordinals and the Hausdorff-Kuratowski theorem In this note, we explore various potential representations of the set of countable ordinals. An equivalence class of representations is then suggested as a standard, as it offers the desired closure properties. With a decent notion of computability on the space of countable ordinals in place, we can then state and prove a computable uniform version of the Hausdorff-Kuratowski theorem. "
no-14128532,arxiv.org/abs/1412.8532,2/1/15,Crash-Tolerant Consensus in Directed Graphs,0,0,0," Crash-Tolerant Consensus in Directed Graphs This work considers a point-to-point network of n nodes connected by directed links, and proves tight necessary and sufficient conditions on the underlying communication graphs for achieving consensus among these nodes under crash faults. We identify the conditions in both synchronous and asynchronous systems "
no-150100507,arxiv.org/abs/1501.00507,2/1/15,Defining and composing big state machines,0,0,0, Defining and composing big state machines A sequence function alternative representation of state machines. 
no-150100526,arxiv.org/abs/1501.00526,2/1/15,Department Management System for Departments of Sri Lankan Universities,0,0,0," Department Management System for Departments of Sri Lankan Universities This paper proposes a new method of data handling as well as implementation of management system for an academic department. Management system is a proven framework for managing and continually improving the organizations policies, procedures and processes. Department of Sri Lankan Universities is a division within a faculty comprising one subject area or a number of related subject areas. The time consumption and error rate of producing information is extremely high. This paper describes how to do the data handling in a department of Sri Lankan Universities using the management system. The efficiency of the management system measured with the amount of data handled by the department. Experiment results shows that this method of data handling increase the efficiency of the department in terms of processing information and the reduction of risks involved with the department activities. "
no-150100512,arxiv.org/abs/1501.00512,2/1/15,Function of Forgetfulness for the Tedium of Oblivion on Liquidity of Ontology Matching,0,0,0," Function of Forgetfulness for the Tedium of Oblivion on Liquidity of Ontology Matching The shallow and fragile knowledge on the Web does not examine in depth the things: it behaves lightly. The conditions created by the Web makes our attention labile and especially fickle, it's unable to concentrate for long as we are trained to surf without going though never in depth. The Web also brings with it the added advantage of a nearly availability infinite knowledge but leads to a loss of the ability to retain and evaluate that knowledge within us increasing forgetfulness of knowledge. In this paper we show how the function of forgetfulness appears linked to tedium and oblivion of knowledge through the liquidity of ontology matching. "
no-14063185,arxiv.org/abs/1406.3185,2/1/15,Generic construction of scale-invariantly coarse grained memory,0,0,0," Generic construction of scale-invariantly coarse grained memory Encoding temporal information from the recent past as spatially distributed activations is essential in order for the entire recent past to be simultaneously accessible. Any biological or synthetic agent that relies on the past to predict/plan the future, would be endowed with such a spatially distributed temporal memory. Simplistically, we would expect that resource limitations would demand the memory system to store only the most useful information for future prediction. For natural signals in real world which show scale free temporal fluctuations, the predictive information encoded in memory is maximal if the past information is scale invariantly coarse grained. Here we examine the general mechanism to construct a scale invariantly coarse grained memory system. Remarkably, the generic construction is equivalent to encoding the linear combinations of Laplace transform of the past information and their approximated inverses. This reveals a fundamental construction constraint on memory networks that attempt to maximize predictive information storage relevant to the natural world. "
no-150100447,arxiv.org/abs/1501.00447,2/1/15,How Perfect Offline Wallets Can Still Leak Bitcoin Private Keys,0,0,0," How Perfect Offline Wallets Can Still Leak Bitcoin Private Keys ECDSA has become a popular choice as lightweight alternative to RSA and classic DL based signature algorithms in recent years. As standardized, the signature produced by ECDSA for a pair of a message and a key is not deterministic. This work shows how this non-deterministic choice can be exploited by an attacker to leak private information through the signature without any side channels, an attack first discovered by Young and Yung for classic DL-based cryptosystems in 1997, and how this attack affects the application of ECDSA in the Bitcoin protocol. "
no-150100528,arxiv.org/abs/1501.00528,2/1/15,Influence of Facebook in Academic Performance of Sri Lankan University Students,0,0,0, Influence of Facebook in Academic Performance of Sri Lankan University Students Facebook is only an electronic communication between human but unfortunately it has become an addiction for all. This paper examines the usage of Facebook among university students and its influence in their academic performance. The impact of Facebook can either be good or bad on university students and in their academic activities. Even though a closer look on the real impact of Facebook reveals that it leads to several problems in university students academic performances. Today Facebook is somehow destroying the future and academic carrier of university students. At the same time also intended to find the significance of use of Facebook by University students in their academic success with the help of a survey conducted to collect the data among more than 250 students of different Universities in Sri Lanka. 
no-150100491,arxiv.org/abs/1501.00491,2/1/15,Mapping and Matching Algorithms: Data Mining by Adaptive Graphs,0,0,0," Mapping and Matching Algorithms: Data Mining by Adaptive Graphs Assume we have two bijective functions and with for all and . Every day and in different locations, we see the different results of and without seeing . We are not assured about the time stamp nor the order within the day but at least the location is fully defined. We want to find the matching between and (i.e., we will not know ). We formulate this problem as an adaptive graph mining: we develop the theory, the solution, and the implementation. This work stems from a practical problem thus our definitions. The solution is simple, clear, and the implementation parallel and efficient. In our experience, the problem and the solution are novel and we want to share our finding. "
no-150100419,arxiv.org/abs/1501.00419,2/1/15,Minimizing the Probability of Ruin in Retirement,0,0,1," Minimizing the Probability of Ruin in Retirement Retirees who exhaust their savings while still alive are said to experience financial ruin. These savings are typically grown during the accumulation phase then spent during the retirement decumulation phase. Extensive research into invest-and-harvest decumulation strategies has been conducted, but recommendations differ markedly. This has likely been a source of concern and confusion for the retiree. Our goal is to find what has heretofore been elusive, namely an optimal decumulation strategy. Optimality implies that no alternate strategy exists or can be constructed that delivers a lower probability of ruin, given a fixed inflation-adjusted withdrawal rate. "
no-150100406,arxiv.org/abs/1501.00406,2/1/15,Multi Detector Fusion of Dynamic TOA Estimation using Kalman Filter,1,0,1," Multi Detector Fusion of Dynamic TOA Estimation using Kalman Filter In this paper, we propose fusion of dynamic TOA (time of arrival) from multiple non-coherent detectors like energy detectors operating at sub-Nyquist rate through Kalman filtering. We also show that by using multiple of these energy detectors, we can achieve the performance of a digital matched filter implementation in the AWGN (additive white Gaussian noise) setting. We derive analytical expression for number of energy detectors needed to achieve the matched filter performance. We demonstrate in simulation the validity of our analytical approach. Results indicate that number of energy detectors needed will be high at low SNRs and converge to a constant number as the SNR increases. We also study the performance of the strategy proposed using IEEE 802.15.4a CM1 channel model and show in simulation that two sub-Nyquist detectors are sufficient to match the performance of digital matched filter. "
no-12120694,arxiv.org/abs/1212.0694,2/1/15,On bounding the bandwidth of graphs with symmetry,0,0,1," On bounding the bandwidth of graphs with symmetry We derive a new lower bound for the bandwidth of a graph that is based on a new lower bound for the minimum cut problem. Our new semidefinite programming relaxation of the minimum cut problem is obtained by strengthening the known semidefinite programming relaxation for the quadratic assignment problem (or for the graph partition problem) by fixing two vertices in the graph; one on each side of the cut. This fixing results in several smaller subproblems that need to be solved to obtain the new bound. In order to efficiently solve these subproblems we exploit symmetry in the data; that is, both symmetry in the min-cut problem and symmetry in the graphs. To obtain upper bounds for the bandwidth of graphs with symmetry, we develop a heuristic approach based on the well-known reverse Cuthill-McKee algorithm, and that improves significantly its performance on the tested graphs. Our approaches result in the best known lower and upper bounds for the bandwidth of all graphs under consideration, i.e., Hamming graphs, 3-dimensional generalized Hamming graphs, Johnson graphs, and Kneser graphs, with up to 216 vertices. "
no-150100375,arxiv.org/abs/1501.00375,2/1/15,Passing Expectation Propagation Messages with Kernel Methods,0,0,0," Passing Expectation Propagation Messages with Kernel Methods We propose to learn a kernel-based message operator which takes as input all expectation propagation EP incoming messages to a factor node and produces an outgoing message. In ordinary EP, computing an outgoing message involves estimating a multivariate integral which may not have an analytic expression. Learning such an operator allows one to bypass the expensive computation of the integral during inference by directly mapping all incoming messages into an outgoing message. The operator can be learned from training data (examples of input and output messages) which allows automated inference to be made on any kind of factor that can be sampled. "
no-13125307,arxiv.org/abs/1312.5307,2/1/15,Seeking Anonymity in an Internet Panopticon,0,0,0," Seeking Anonymity in an Internet Panopticon Obtaining and maintaining anonymity on the Internet is challenging. The state of the art in deployed tools, such as Tor, uses onion routing OR to relay encrypted connections on a detour passing through randomly chosen relays scattered around the Internet. Unfortunately, OR is known to be vulnerable at least in principle to several classes of attacks for which no solution is known or believed to be forthcoming soon. Current approaches to anonymity also appear unable to offer accurate, principled measurement of the level or quality of anonymity a user might obtain. Toward this end, we offer a high-level view of the Dissent project, the first systematic effort to build a practical anonymity system based purely on foundations that offer measurable and formally provable anonymity properties. Dissent builds on two key pre-existing primitives - verifiable shuffles and dining cryptographers - but for the first time shows how to scale such techniques to offer measurable anonymity guarantees to thousands of participants. Further, Dissent represents the first anonymity system designed from the ground up to incorporate some systematic countermeasure for each of the major classes of known vulnerabilities in existing approaches, including global traffic analysis, active attacks, and intersection attacks. Finally, because no anonymity protocol alone can address risks such as software exploits or accidental self-identification, we introduce WiNon, an experimental operating system architecture to harden the uses of anonymity tools such as Tor and Dissent against such attacks. "
no-150100513,arxiv.org/abs/1501.00513,2/1/15,Self-Repairing Disk Arrays,0,0,0," Self-Repairing Disk Arrays As the prices of magnetic storage continue to decrease, the cost of replacing failed disks becomes increasingly dominated by the cost of the service call itself. We propose to eliminate these calls by building disk arrays that contain enough spare disks to operate without any human intervention during their whole lifetime. To evaluate the feasibility of this approach, we have simulated the behavior of two-dimensional disk arrays with n parity disks and n(n-1)/2 data disks under realistic failure and repair assumptions. Our conclusion is that having n(n+1)/2 spare disks is more than enough to achieve a 99.999 percent probability of not losing data over four years. We observe that the same objectives cannot be reached with RAID level 6 organizations and would require RAID stripes that could tolerate triple disk failures. "
no-14125557,arxiv.org/abs/1412.5557,2/1/15,Standing Together for Reproducibility in Large-Scale Computing: Report on reproducibility@XSEDE,0,0,0," Standing Together for Reproducibility in Large-Scale Computing: Report on reproducibility@XSEDE This is the final report on reproducibility@xsede, a one-day workshop held in conjunction with XSEDE14, the annual conference of the Extreme Science and Engineering Discovery Environment XSEDE. The workshop's discussion-oriented agenda focused on reproducibility in large-scale computational research. Two important themes capture the spirit of the workshop submissions and discussions: (1) organizational stakeholders, especially supercomputer centers, are in a unique position to promote, enable, and support reproducible research; and (2) individual researchers should conduct each experiment as though someone will replicate that experiment. Participants documented numerous issues, questions, technologies, practices, and potentially promising initiatives emerging from the discussion, but also highlighted four areas of particular interest to XSEDE: (1) documentation and training that promotes reproducible research; (2) system-level tools that provide build- and run-time information at the level of the individual job; (3) the need to model best practices in research collaborations involving XSEDE staff; and (4) continued work on gateways and related technologies. In addition, an intriguing question emerged from the day's interactions: would there be value in establishing an annual award for excellence in reproducible research? "
no-14012753,arxiv.org/abs/1401.2753,2/1/15,Stochastic Optimization with Importance Sampling,0,0,0," Stochastic Optimization with Importance Sampling Uniform sampling of training data has been commonly used in traditional stochastic optimization algorithms such as Proximal Stochastic Gradient Descent (prox-SGD) and Proximal Stochastic Dual Coordinate Ascent (prox-SDCA). Although uniform sampling can guarantee that the sampled stochastic quantity is an unbiased estimate of the corresponding true quantity, the resulting estimator may have a rather high variance, which negatively affects the convergence of the underlying optimization procedure. In this paper we study stochastic optimization with importance sampling, which improves the convergence rate by reducing the stochastic variance. Specifically, we study prox-SGD (actually, stochastic mirror descent) with importance sampling and prox-SDCA with importance sampling. For prox-SGD, instead of adopting uniform sampling throughout the training process, the proposed algorithm employs importance sampling to minimize the variance of the stochastic gradient. For prox-SDCA, the proposed importance sampling scheme aims to achieve higher expected dual value at each dual coordinate ascent step. We provide extensive theoretical analysis to show that the convergence rates with the proposed importance sampling methods can be significantly improved under suitable conditions both for prox-SGD and for prox-SDCA. Experiments are provided to verify the theoretical analysis. "
no-150100567,arxiv.org/abs/1501.00567,3/1/15,Adaptive Dispatching of Tasks in the Cloud,0,0,0," Adaptive Dispatching of Tasks in the Cloud The increasingly wide application of Cloud Computing enables the consolidation of tens of thousands of applications in shared infrastructures. Thus, meeting the quality of service requirements of so many diverse applications in such shared resource environments has become a real challenge, especially since the characteristics and workload of applications differ widely and may change over time. This paper presents an experimental system that can exploit a variety of online quality of service aware adaptive task allocation schemes, and three such schemes are designed and compared. These are a measurement driven algorithm that uses reinforcement learning, secondly a sensible allocation algorithm that assigns jobs to sub-systems that are observed to provide a lower response time, and then an algorithm that splits the job arrival stream into sub-streams at rates computed from the hosts' processing capabilities. All of these schemes are compared via measurements among themselves and with a simple round-robin scheduler, on two experimental test-beds with homogeneous and heterogeneous hosts having different processing capacities. "
no-150100561,arxiv.org/abs/1501.00561,3/1/15,A linear-time algorithm for the geodesic center of a simple polygon,0,0,0," A linear-time algorithm for the geodesic center of a simple polygon Given two points in a simple polygon of vertices, its geodesic distance is the length of the shortest path that connects them among all paths that stay within . The geodesic center of is the unique point in that minimizes the largest geodesic distance to all other points of . In 1989, Pollack, Sharir and Rote [Disc. \& Comput. Geom. 89] showed an time algorithm that computes the geodesic center of . Since then, a longstanding question has been whether this running time can be improved (explicitly posed by Mitchell [Handbook of Computational Geometry, 2000]). In this paper we affirmatively answer this question and present a linear time algorithm to solve this problem. "
no-150100579,arxiv.org/abs/1501.00579,3/1/15,A Model Study of an All-Digital  Discrete-Time and Embedded Linear Regulator,0,0,0," A Model Study of an All-Digital, Discrete-Time and Embedded Linear Regulator With an increasing number of power-states, finer- grained power management and larger dynamic ranges of digital circuits, the integration of compact, scalable linear-regulators embedded deep within logic blocks has become important. While analog linear-regulators have traditionally been used in digital ICs, the need for digitally implementable designs that can be synthesized and embedded in digital functional units for ultra fine- grained power management has emerged. This paper presents the circuit design and control models of an all-digital, discrete-time linear regulator and explores the parametric design space for transient response time and loop stability. "
no-150100602,arxiv.org/abs/1501.00602,3/1/15,An analogue of Vosper's Theorem for Extension Fields,1,0,1," An analogue of Vosper's Theorem for Extension Fields We are interested in characterising pairs of linear subspaces in a field extension such that the linear span of the set of products of elements of and of elements of has small dimension. Our central result is a linear analogue of Vosper's Theorem, which gives the structure of vector spaces in a prime extension of a finite field for which , when and . "
no-150100569,arxiv.org/abs/1501.00569,3/1/15,A Transfer Theorem for the Separation Problem,0,0,0," A Transfer Theorem for the Separation Problem We investigate two problems for a class C of regular word languages. The C-membership problem asks for an algorithm to decide whether an input language belongs to C. The C-separation problem asks for an algorithm that, given as input two regular languages, decides whether there exists a third language in C containing the first language, while being disjoint from the second. These problems are considered as means to obtain a deep understanding of the class C. It is usual for such classes to be defined by logical formalisms. Logics are often built on top of each other, by adding new predicates. A natural construction is to enrich a logic with the successor relation. In this paper, we obtain simple self-contained proofs of two transfer results: we show that for suitable logically defined classes, the membership, resp. the separation problem for a class enriched with the successor relation reduces to the same problem for the original class. Our reductions work both for languages of finite words and infinite words. The proofs are mostly self-contained, and only require a basic background on regular languages. This paper therefore gives new, simple proofs of results that were considered as difficult, such as the decid- ability of the membership problem for the levels 1, 3/2, 2 and 5/2 of the dot-depth hierarchy. "
no-150100549,arxiv.org/abs/1501.00549,3/1/15,Can Fires  Night Lights  and Mobile Phones reveal behavioral fingerprints useful for Development?,0,0,0," Can Fires, Night Lights, and Mobile Phones reveal behavioral fingerprints useful for Development? Fires, lights at night and mobile phone activity have been separately used as proxy indicators of human activity with high potential for measuring human development. In this preliminary report, we develop some tools and methodologies to identify and visualize relations among remote sensing datasets containing fires and night lights information with mobile phone activity in Cote D'Ivoire from December 2011 to April 2012. "
no-14127059,arxiv.org/abs/1412.7059,3/1/15,Cloud Enabled Emergency Navigation Using Faster-than-real-time Simulation,0,0,0," Cloud Enabled Emergency Navigation Using Faster-than-real-time Simulation State-of-the-art emergency navigation approaches are designed to evacuate civilians during a disaster based on real-time decisions using a pre-defined algorithm and live sensory data. Hence, casualties caused by the poor decisions and guidance are only apparent at the end of the evacuation process and cannot then be remedied. Previous research shows that the performance of routing algorithms for evacuation purposes are sensitive to the initial distribution of evacuees, the occupancy levels, the type of disaster and its as well its locations. Thus an algorithm that performs well in one scenario may achieve bad results in another scenario. This problem is especially serious in heuristic-based routing algorithms for evacuees where results are affected by the choice of certain parameters. Therefore, this paper proposes a simulation-based evacuee routing algorithm that optimises evacuation by making use of the high computational power of cloud servers. Rather than guiding evacuees with a predetermined routing algorithm, a robust Cognitive Packet Network based algorithm is first evaluated via a cloud-based simulator in a faster-than-real-time manner, and any simulated casualties are then re-routed using a variant of Dijkstra's algorithm to obtain new safe paths for them to exits. This approach can be iterated as long as corrective action is still possible. "
no-14022269,arxiv.org/abs/1402.2269,3/1/15,Dining Cryptographers are Practical,0,0,0," Dining Cryptographers are Practical The dining cryptographers protocol provides information-theoretically secure sender and recipient untraceability. However, the protocol is considered to be impractical because a malicious participant may disrupt the communication. We propose an implementation which provides information-theoretical security for senders and recipients, and in which a disruptor with limited computational capabilities can easily be detected. "
no-14021732,arxiv.org/abs/1402.1732,3/1/15,Dining Cryptographers with 0.924 Verifiable Collision Resolution,0,0,0, Dining Cryptographers with 0.924 Verifiable Collision Resolution The dining cryptographers protocol implements a multiple access channel in which senders and recipients are anonymous. A problem is that a malicious participant can disrupt communication by deliberately creating collisions. We propose a computationally secure dining cryptographers protocol with collision resolution that achieves a maximum stable throughput of 0.924 messages per round and which allows to easily detect disruptors. 
no-14015093,arxiv.org/abs/1401.5093,3/1/15,Localization and centrality in networks,0,0,0," Localization and centrality in networks Eigenvector centrality is a common measure of the importance of nodes in a network. Here we show that under common conditions the eigenvector centrality displays a localization transition that causes most of the weight of the centrality to concentrate on a small number of nodes in the network. In this regime the measure is no longer useful for distinguishing among the remaining nodes and its efficacy as a network metric is impaired. As a remedy, we propose an alternative centrality measure based on the nonbacktracking matrix, which gives results closely similar to the standard eigenvector centrality in dense networks where the latter is well behaved, but avoids localization and gives useful results in regimes where the standard centrality fails. "
no-150100624,arxiv.org/abs/1501.00624,3/1/15,Maximal Noise in Interactive Communication over Erasure Channels and Channels with Feedback,0,0,0," Maximal Noise in Interactive Communication over Erasure Channels and Channels with Feedback We provide tight upper and lower bounds on the noise resilience of interactive communication over noisy channels with feedback. In this setting, we show that the maximal fraction of noise that any robust protocol can resist is 1/3. Additionally, we provide a simple and efficient robust protocol that succeeds as long as the fraction of noise is at most 1/3 - \epsilon. Surprisingly, both bounds hold regardless of whether the parties send bits or symbols from an arbitrarily large alphabet. We also consider interactive communication over erasure channels. We provide a protocol that matches the optimal tolerable erasure rate of 1/2 - \epsilon of previous protocols (Franklin et al., CRYPTO '13) but operates in a much simpler and more efficient way. Our protocol works with an alphabet of size 4, in contrast to prior protocols in which the alphabet size grows as epsilon goes to zero. Building on the above algorithm with a fixed alphabet size, we are able to devise a protocol for binary erasure channels that tolerates erasure rates of up to 1/3 - \epsilon. "
no-150100539,arxiv.org/abs/1501.00539,3/1/15,Maximum R\'enyi Entropy Rate,1,0,1," Maximum R\'enyi Entropy Rate Two maximization problems of R\'enyi entropy rate are investigated: the maximization over all stochastic processes whose marginals satisfy a linear constraint, and the Burg-like maximization over all stochastic processes whose autocovariance function begins with some given values. The solutions are related to the solutions to the analogous maximization problems of Shannon entropy rate. "
no-14081258,arxiv.org/abs/1408.1258,3/1/15,On Practical Regular Expressions,0,0,0," On Practical Regular Expressions We report on simulation, hierarchy, and decidability results for Practical Regular Expressions PRE, which may include back references in addition to the standard operations union, concatenation, and star. The following results are obtained: PRE can be simulated by the classical model of nondeterministic finite automata with sensing one-way heads. The number of heads depends on the number of different variables in the expressions. A space bound O(n log m) for matching a text of length m with a PRE with n variables based on the previous simulation. This improves the bound O(nm) from (C\^ampeanu and Santean 2009). PRE cannot be simulated by deterministic finite automata with at most three sensing one-way heads or deterministic finite automata with any number of non-sensing one-way heads. PRE with a bounded number of occurrences of variables in any match can be simulated by nondeterministic finite automata with one-way heads. There is a tight hierarchy of PRE with a growing number of non-nested variables over a fixed alphabet. A previously known hierarchy was based on nested variables and growing alphabets (Larsen 1998). Matching of PRE without star over a single-letter alphabet is NP-complete. This strengthens the corresponding result for expressions over larger alphabets and with star (Aho 1990). Inequivalence of PRE without closure operators is Sigma^P_2-complete. The decidability of universality of PRE over a single letter alphabet is linked to the existence of Fermat Primes. Greibach's Theorem applies to languages characterized by PRE. "
no-14078383,arxiv.org/abs/1407.8383,3/1/15,On the necessity of looped-functionals arising in the analysis of pseudo-periodic  sampled-data and hybrid systems,0,0,1," On the necessity of looped-functionals arising in the analysis of pseudo-periodic, sampled-data and hybrid systems Looped-functionals have been shown to be relevant for the analysis of a wide variety of systems. However, the conditions obtained in previous works on the analysis of sampled-data, impulsive and switched systems have only been shown to be sufficient for the characterization of their associated discrete-time stability conditions. We prove here that these conditions are also \necessary. This result is derived for a wider class of linear systems, referred to as impulsive pseudo-periodic systems, that encompass periodic, impulsive, sampled-data and switched systems as special cases. "
no-150100606,arxiv.org/abs/1501.00606,3/1/15,Optimized Implementation of Memristor-Based Full Adder by Material Implication Logic,0,0,0," Optimized Implementation of Memristor-Based Full Adder by Material Implication Logic Recently memristor-based applications and circuits are receiving an increased attention. Furthermore, memristors are also applied in logic circuit design. Material implication logic is one of the main areas with memristors. In this paper an optimized memristor-based full adder design by material implication logic is presented. This design needs 27 memristors and less area in comparison with typical CMOS-based 8-bit full adders. Also the presented full adder needs only 184 computational steps which enhance former full adder design speed by 20 percent. "
no-150100619,arxiv.org/abs/1501.00619,3/1/15,Outage Probability of Overhearing Amplify-and-Forward Cooperative Relaying,1,0,1," Outage Probability of Overhearing Amplify-and-Forward Cooperative Relaying This paper investigates the outage performance of overhearing amplify-and-forward AF cooperative relaying, where a source transmits information to its destination through multiple helping overhearing AF relays with space-time network coding STNC employed. Firstly, the transmission protocol of such a relaying system, i.e., cooperative relaying with overhearing AF relays based on STNC (STNC-OHAF) is presented. Then, the instantaneous end-to-end SNR expression of STNC-OHAF is analysed. Based on this, an explicit expression of the outage probability for STNC-OHAF over independent but not necessarily identically distributed (i.n.i.d) Rayleigh fading channels is theoretically derived. Numerical results validate our theoretical analysis and show that by introducing overhearing among relays, the outage performance of the system can be greatly improved. It also shows that there is a trade-off between system sum outage capacity and the transmitted number of symbols. "
no-150100587,arxiv.org/abs/1501.00587,3/1/15,Prioritized Random MAC Optimization via Graph-based Analysis,1,0,1," Prioritized Random MAC Optimization via Graph-based Analysis Motivated by the analogy between successive interference cancellation and iterative belief-propagation on erasure channels, irregular repetition slotted ALOHA IRSA strategies have received a lot of attention in the design of medium access control protocols. The IRSA schemes have been mostly analyzed for theoretical scenarios for homogenous sources, where they are shown to substantially improve the system performance compared to classical slotted ALOHA protocols. In this work, we consider generic systems where sources in different importance classes compete for a common channel. We propose a new prioritized IRSA algorithm and derive the probability to correctly resolve collisions for data from each source class. We then make use of our theoretical analysis to formulate a new optimization problem for selecting the transmission strategies of heterogenous sources. We optimize both the replication probability per class and the source rate per class, in such a way that the overall system utility is maximized. We then propose a heuristic-based algorithm for the selection of the transmission strategy, which is built on intrinsic characteristics of the iterative decoding methods adopted for recovering from collisions. Experimental results validate the accuracy of the theoretical study and show the gain of well-chosen prioritized transmission strategies for transmission of data from heterogenous classes over shared wireless channels. "
no-150100559,arxiv.org/abs/1501.00559,3/1/15,The Learnability of Unknown Quantum Measurements,0,0,0," The Learnability of Unknown Quantum Measurements Quantum machine learning has received significant attention in recent years, and promising progress has been made in the development of quantum algorithms to speed up traditional machine learning tasks. In this work, however, we focus on investigating the information-theoretic upper bounds of sample complexity - how many training samples are sufficient to predict the future behaviour of an unknown target function. This kind of problem is, arguably, one of the most fundamental problems in statistical learning theory and the bounds for practical settings can be completely characterised by a simple measure of complexity. Our main result in the paper is that, for learning an unknown quantum measurement, the upper bound, given by the fat-shattering dimension, is linearly proportional to the dimension of the underlying Hilbert space. Learning an unknown quantum state becomes a dual problem to ours, and as a byproduct, we can recover Aaronson's famous result [Proc. R. Soc. A 463:3089-3144 (2007)] solely using a classical machine learning technique. In addition, other famous complexity measures like covering numbers and Rademacher complexities are derived explicitly. We are able to connect measures of sample complexity with various areas in quantum information science, e.g. quantum state/measurement tomography, quantum state discrimination and quantum random access codes, which may be of independent interest. Lastly, with the assistance of general Bloch-sphere representation, we show that learning quantum measurements/states can be mathematically formulated as a neural network. Consequently, classical ML algorithms can be applied to efficiently accomplish the two quantum learning tasks. "
no-150100614,arxiv.org/abs/1501.00614,3/1/15,Understanding Trajectory Behavior: A Motion Pattern Approach,0,1,0," Understanding Trajectory Behavior: A Motion Pattern Approach Mining the underlying patterns in gigantic and complex data is of great importance to data analysts. In this paper, we propose a motion pattern approach to mine frequent behaviors in trajectory data. Motion patterns, defined by a set of highly similar flow vector groups in a spatial locality, have been shown to be very effective in extracting dominant motion behaviors in video sequences. Inspired by applications and properties of motion patterns, we have designed a framework that successfully solves the general task of trajectory clustering. Our proposed algorithm consists of four phases: flow vector computation, motion component extraction, motion component's reachability set creation, and motion pattern formation. For the first phase, we break down trajectories into flow vectors that indicate instantaneous movements. In the second phase, via a Kmeans clustering approach, we create motion components by clustering the flow vectors with respect to their location and velocity. Next, we create motion components' reachability set in terms of spatial proximity and motion similarity. Finally, for the fourth phase, we cluster motion components using agglomerative clustering with the weighted Jaccard distance between the motion components' signatures, a set created using path reachability. We have evaluated the effectiveness of our proposed method in an extensive set of experiments on diverse datasets. Further, we have shown how our proposed method handles difficulties in the general task of trajectory clustering that challenge the existing state-of-the-art methods. "
no-14128313,arxiv.org/abs/1412.8313,3/1/15,Wireless Information and Energy Transfer for Decode-and-Forward Relaying MIMO-OFDM Networks,1,0,1," Wireless Information and Energy Transfer for Decode-and-Forward Relaying MIMO-OFDM Networks This paper investigates the system achievable rate and optimization for the multiple-input multiple-output MIMO-orthogonal frequency division multiplexing OFDM system with an energy harvesting EH relay. Firstly we propose a time switchingbased relaying TSR protocol to enable the simultaneous information processing and energy harvesting at the relay. Then, we discuss its achievable rate performance theoretically and formulated an optimization problem to maximize the system achievable rate. As the problem is difficult to solve, we design an Augmented Lagrangian Penalty Function ALPF method for it. Extensive simulation results are provided to demonstrate the accuracy of the analytical results and the effectiveness of the ALPF method. "
no-150100656,arxiv.org/abs/1501.00656,4/1/15,Algebraic Analysis Applied to the Theory of Linear Dynamical Systems,0,0,1," Algebraic Analysis Applied to the Theory of Linear Dynamical Systems The expression Algebraic Analysis was coined by Mikio Sato. It consists of using algebraic notions to solve analytic problem. The origin of Algebraic Analysis is Algebraic Geometry as was developed by Alexander Grothendieck and his school. Mimicking the introduction of Grothendieck's EGA (changing only a few words) one obtains a good definition of the modern theory of linear dynamical systems, as developed by Michel Fliess, Ian Willems, Ulrich Oberst and others. "
no-150100721,arxiv.org/abs/1501.00721,4/1/15,Approximation Algorithms for Low-Density Graphs,0,0,0," Approximation Algorithms for Low-Density Graphs We study the family of intersection graphs of low density objects in low dimensional Euclidean space. This family is quite general, and includes planar graphs. We prove that such graphs have small separators. Next, we present efficient approximation algorithms for these graphs, for Independent Set, Set Cover, and Dominating Set problems, among others. We also prove corresponding hardness of approximation for some of these optimization problems, providing a characterization of their intractability in terms of density. "
no-150100669,arxiv.org/abs/1501.00669,4/1/15,Asynchronous Programming in a Prioritized Form,0,0,0," Asynchronous Programming in a Prioritized Form Asynchronous programming has appeared as a programming style that overcomes undesired properties of concurrent programming. Typically in asynchronous models of programming, methods are posted into a post list for latter execution. The order of method executions is serial, but nondeterministic. This paper presents a new and simple, yet powerful, model for asynchronous programming. The proposed model consists of two components; a context-free grammar and an operational semantics. The model is supported by the ability to express important applications. An advantage of our model over related work is that the model simplifies the way posted methods are assigned priorities. Another advantage is that the operational semantics uses the simple concept of singly linked list to simulate the prioritized process of methods posting and execution. The simplicity and expressiveness make it relatively easy for analysis algorithms to disclose the otherwise un-captured programming bugs in asynchronous programs. "
no-150100676,arxiv.org/abs/1501.00676,4/1/15,A variational formula for risk-sensitive reward,1,0,1," A variational formula for risk-sensitive reward We derive a variational formula for the optimal growth rate of reward in the infinite horizon risk-sensitive control problem for discrete time Markov decision processes with compact metric state and action spaces, extending a formula of Donsker and Varadhan for the Perron-Frobenius eigenvalue of a positive operator. This leads to a concave maximization formulation of the problem of determining this optimal growth rate. "
no-14125227,arxiv.org/abs/1412.5227,4/1/15,BER-Based Physical Layer Security with Finite Codelength: Combining Strong Converse and Error Amplification,1,0,1," BER-Based Physical Layer Security with Finite Codelength: Combining Strong Converse and Error Amplification A bit error rate BER-based physical layer security approach is proposed for finite blocklength. For secure communication in the sense of high BER, the information-theoretic strong converse is combined with cryptographic error amplification achieved by substitution permutation networks (SPNs) based on confusion and diffusion. For discrete memoryless channels (DMCs), an analytical framework is provided showing the tradeoffs among finite blocklength, maximum/minimum possible transmission rates, and BER requirements for the legitimate receiver and the eavesdropper. Also, the security gap is analytically studied for Gaussian channels and the concept is extended to other DMCs including binary symmetric channels (BSCs) and binary erasure channels (BECs). For fading channels, the transmit power is optimized to minimize the outage probability of the legitimate receiver subject to a BER threshold for the eavesdropper. "
no-14010852,arxiv.org/abs/1401.0852,4/1/15,Concave Penalized Estimation of Sparse Gaussian Bayesian Networks,0,0,0," Concave Penalized Estimation of Sparse Gaussian Bayesian Networks We develop a penalized likelihood estimation framework to estimate the structure of Gaussian Bayesian networks from observational data. In contrast to recent methods which accelerate the learning problem by restricting the search space, our main contribution is a fast algorithm for score-based structure learning which does not restrict the search space in any way and works on high-dimensional datasets with thousands of variables. Our use of concave regularization, as opposed to the more popular (e.g. BIC) penalty, is new. Moreover, we provide theoretical guarantees which generalize existing asymptotic results when the underlying distribution is Gaussian. Most notably, our framework does not require the existence of a so-called faithful DAG representation, and as a result the theory must handle the inherent nonidentifiability of the estimation problem in a novel way. Finally, as a matter of independent interest, we provide a comprehensive comparison of our approach to several standard structure learning methods using open-source packages developed for the R language. Based on these experiments, we show that our algorithm is significantly faster than other competing methods while obtaining higher sensitivity with comparable false discovery rates for high-dimensional data. In particular, the total runtime for our method to generate a solution path of 20 estimates for DAGs with 8000 nodes is around one hour. "
no-150100720,arxiv.org/abs/1501.00720,4/1/15,Concept-oriented programming: from classes to concepts and from inheritance to inclusion,0,0,0," Concept-oriented programming: from classes to concepts and from inheritance to inclusion For the past several decades, programmers have been modeling things in the world with trees using hierarchies of classes and object-oriented programming OOP languages. In this paper, we describe a novel approach to programming, called concept-oriented programming COP, which generalizes classes and inheritance by introducing concepts and inclusion, respectively. "
no-150100728,arxiv.org/abs/1501.00728,4/1/15,Differential Search Algorithm-based Parametric Optimization of Fuzzy Generalized Eigenvalue Proximal Support Vector Machine,0,0,0," Differential Search Algorithm-based Parametric Optimization of Fuzzy Generalized Eigenvalue Proximal Support Vector Machine Support Vector Machine SVM is an effective model for many classification problems. However, SVM needs the solution of a quadratic program which require specialized code. In addition, SVM has many parameters, which affects the performance of SVM classifier. Recently, the Generalized Eigenvalue Proximal SVM GEPSVM has been presented to solve the SVM complexity. In real world applications data may affected by error or noise, working with this data is a challenging problem. In this paper, an approach has been proposed to overcome this problem. This method is called DSA-GEPSVM. The main improvements are carried out based on the following: 1) a novel fuzzy values in the linear case. 2) A new Kernel function in the nonlinear case. 3) Differential Search Algorithm DSA is reformulated to find near optimal values of the GEPSVM parameters and its kernel parameters. The experimental results show that the proposed approach is able to find the suitable parameter values, and has higher classification accuracy compared with some other algorithms. "
no-150100677,arxiv.org/abs/1501.00677,4/1/15,Group-based ranking method for online rating systems with spamming attacks,0,0,0," Group-based ranking method for online rating systems with spamming attacks Ranking problem has attracted much attention in real systems. How to design a robust ranking method is especially significant for online rating systems under the threat of spamming attacks. By building reputation systems for users, many well-performed ranking methods have been applied to address this issue. In this Letter, we propose a group-based ranking method that evaluates users' reputations based on their grouping behaviors. More specifically, users are assigned with high reputation scores if they always fall into large rating groups. Results on three real data sets indicate that the present method is more accurate and robust than correlation-based method in the presence of spamming attacks. "
no-150100744,arxiv.org/abs/1501.00744,4/1/15,Identifying Relevant Document Facets for Keyword-Based Search Queries,0,0,0," Identifying Relevant Document Facets for Keyword-Based Search Queries As structured documents with rich metadata (such as products, movies, etc.) become increasingly prevalent, searching those documents has become an important IR problem. Although advanced search interfaces are widely available, most users still prefer to use keyword-based queries to search those documents. Query keywords often imply some hidden restrictions on the desired documents, which can be represented as document facet-value pairs. To achieve high retrieval performance, it's important to be able to identify the relevant facet-value pairs hidden in a query. In this paper, we study the problem of identifying document facet-value pairs that are relevant to a keyword-based search query. We propose a machine learning approach and a set of useful features, and evaluate our approach using a movie data set from INEX. "
no-150100742,arxiv.org/abs/1501.00742,4/1/15,LEQA: Latency Estimation for a Quantum Algorithm Mapped to a Quantum Circuit Fabric,0,0,0," LEQA: Latency Estimation for a Quantum Algorithm Mapped to a Quantum Circuit Fabric This paper presents LEQA, a fast latency estimation tool for evaluating the performance of a quantum algorithm mapped to a quantum fabric. The actual quantum algorithm latency can be computed by performing detailed scheduling, placement and routing of the quantum instructions and qubits in a quantum operation dependency graph on a quantum circuit fabric. This is, however, a very expensive proposition that requires large amounts of processing time. Instead, LEQA, which is based on computing the neighborhood population counts of qubits, can produce estimates of the circuit latency with good accuracy (i.e., an average of less than 3% error) with up to two orders of magnitude speedup for mid-size benchmarks. This speedup is expected to increase superlinearly as a function of circuit size (operation count). "
no-150100644,arxiv.org/abs/1501.00644,4/1/15,Markov Decision Processes with Applications in Wireless Sensor Networks: A Survey,0,0,0," Markov Decision Processes with Applications in Wireless Sensor Networks: A Survey Wireless sensor networks (WSNs) consist of autonomous and resource-limited devices. The devices cooperate to monitor one or more physical phenomena within an area of interest. WSNs operate as stochastic systems because of randomness in the monitored environments. For long service time and low maintenance cost, WSNs require adaptive and robust methods to address data exchange, topology formulation, resource and power optimization, sensing coverage and object detection, and security challenges. In these problems, sensor nodes are to make optimized decisions from a set of accessible strategies to achieve design goals. This survey reviews numerous applications of the Markov decision process MDP framework, a powerful decision-making tool to develop adaptive algorithms and protocols for WSNs. Furthermore, various solution methods are discussed and compared to serve as a guide for using MDPs in WSNs. "
no-150100758,arxiv.org/abs/1501.00758,4/1/15,Mathematical model for hit phenomena and its application to analyze popularity of weekly tv drama,0,0,0," Mathematical model for hit phenomena and its application to analyze popularity of weekly tv drama Mathematical model for hit phenomena presented by A Ishii et al in 2012 has been extended to analyze and predict a lot of hit subject using social network system. The equation for each individual consumers is assumed and the equation of social response to each hit subject is derived as stochastic process of statistical physics. The advertisement effect is included as external force and the communication effects are included as two-body and three-body interaction. The applications of this model are demonstrated for analyzing population of weekly TV drama. Including both the realtime view data and the playback view data, we found that the indirect communication correlate strongly to the TV viewing rate data for recent Japanese 20 TV drama. "
no-14104145,arxiv.org/abs/1410.4145,4/1/15,Maze solving Algorithm for line following robot and derivation of linear path distance from nonlinear path,0,0,0," Maze solving Algorithm for line following robot and derivation of linear path distance from nonlinear path In this paper we have discussed a unique general algorithm for exploring and solving any kind of line maze with another simple one for simple mazes without loops or loops having highest two branches none of which are inward. For the general algorithm, we need a method to map the whole maze, which is required if the maze is complex. The proposed maze mapping system is based on coordinate system and after mapping the whole maze as a graph in standard 'Adjacency-list representation' method, shortest path and shortest time path was extracted using Dijkstra's algorithm. In order to find the coordinates of the turning points and junctions, linear distance between the points are needed, for which wheel encoder was used. However, due to non-linear movement of robot, the directly measured distance from the encoder has some error and to remove this error an idea is built up which ended by deriving equations that gives us almost exact linear distance between two points from the reading of wheel encoder of the robot moving in a non-linear path. "
no-150100715,arxiv.org/abs/1501.00715,4/1/15,Mechanism Design for Team Formation,0,0,0," Mechanism Design for Team Formation Team formation is a core problem in AI. Remarkably, little prior work has addressed the problem of mechanism design for team formation, accounting for the need to elicit agents' preferences over potential teammates. Coalition formation in the related hedonic games has received much attention, but only from the perspective of coalition stability, with little emphasis on the mechanism design objectives of true preference elicitation, social welfare, and equity. We present the first formal mechanism design framework for team formation, building on recent combinatorial matching market design literature. We exhibit four mechanisms for this problem, two novel, two simple extensions of known mechanisms from other domains. Two of these (one new, one known) have desirable theoretical properties. However, we use extensive experiments to show our second novel mechanism, despite having no theoretical guarantees, empirically achieves good incentive compatibility, welfare, and fairness. "
no-150100687,arxiv.org/abs/1501.00687,4/1/15,On Enhancing The Performance Of Nearest Neighbour Classifiers Using Hassanat Distance Metric,0,0,0," On Enhancing The Performance Of Nearest Neighbour Classifiers Using Hassanat Distance Metric We showed in this work how the Hassanat distance metric enhances the performance of the nearest neighbour classifiers. The results demonstrate the superiority of this distance metric over the traditional and most-used distances, such as Manhattan distance and Euclidian distance. Moreover, we proved that the Hassanat distance metric is invariant to data scale, noise and outliers. Throughout this work, it is clearly notable that both ENN and IINC performed very well with the distance investigated, as their accuracy increased significantly by 3.3% and 3.1% respectively, with no significant advantage of the ENN over the IINC in terms of accuracy. Correspondingly, it can be noted from our results that there is no optimal algorithm that can solve all real-life problems perfectly; this is supported by the no-free-lunch theorem "
no-12080812,arxiv.org/abs/1208.0812,4/1/15,On the chromatic number of a random hypergraph,0,0,1," On the chromatic number of a random hypergraph We consider the problem of colouring a random uniform hypergraph with vertices and edges, where , , remain constant as tends to infinity. Achlioptas and Naor showed that the chromatic number of a random graph in this setting, the case , must have one of two easily computable values as tends to infinity. We give a complete generalisation of this result to random uniform hypergraphs. "
no-150100671,arxiv.org/abs/1501.00671,4/1/15,On the Complexity of Noncommutative Polynomial Factorization,0,0,0," On the Complexity of Noncommutative Polynomial Factorization In this paper we study the complexity of factorization of polynomials in the free noncommutative ring of polynomials over the field and noncommuting variables . Our main results are the following. Although is not a unique factorization ring, we note that variable-disjoint factorization in has the uniqueness property. Furthermore, we prove that computing the variable-disjoint factorization is polynomial-time equivalent to Polynomial Identity Testing (both when the input polynomial is given by an arithmetic circuit or an algebraic branching program). We also show that variable-disjoint factorization in the black-box setting can be efficiently computed (where the factors computed will be also given by black-boxes, analogous to the work [KT91] in the commutative setting). As a consequence of the previous result we show that homogeneous noncommutative polynomials and multilinear noncommutative polynomials have unique factorizations in the usual sense, which can be efficiently computed. Finally, we discuss a polynomial decomposition problem in which is a natural generalization of homogeneous polynomial factorization and prove some complexity bounds for it. "
no-14060609,arxiv.org/abs/1406.0609,4/1/15,Optimization for Speculative Execution of Multiple Jobs in a MapReduce-like Cluster,0,0,0," Optimization for Speculative Execution of Multiple Jobs in a MapReduce-like Cluster Nowadays, a computing cluster in a typical data center can easily consist of hundreds of thousands of commodity servers, making component/ machine failures the norm rather than exception. A parallel processing job can be delayed substantially as long as one of its many tasks is being assigned to a failing machine. To tackle this so-called straggler problem, most parallel processing frameworks such as MapReduce have adopted various strategies under which the system may speculatively launch additional copies of the same task if its progress is abnormally slow or simply because extra idling resource is available. In this paper, we focus on the design of speculative execution schemes for a parallel processing cluster under different loading conditions. For the lightly loaded case, we analyze and propose two optimization-based schemes, namely, the Smart Cloning Algorithm SCA which is based on maximizing the job utility and the Straggler Detection Algorithm SDA which minimizes the overall resource consumption of a job. We also derive the workload threshold under which SCA or SDA should be used for speculative execution. Our simulation results show both SCA and SDA can reduce the job flowtime by nearly 60% comparing to the speculative execution strategy of Microsoft Mantri. For the heavily loaded case, we propose the Enhanced Speculative Execution ESE algorithm which is an extension of the Microsoft Mantri scheme. We show that the ESE algorithm can beat the Mantri baseline scheme by 18% in terms of job flowtime while consuming the same amount of resource. "
no-150100638,arxiv.org/abs/1501.00638,4/1/15,Parking Space Management via Dynamic Performance-Based Pricing,0,0,0," Parking Space Management via Dynamic Performance-Based Pricing In congested urban areas, it remains a pressing challenge to reduce unnecessary vehicle circling for parking while at the same time maximize parking space utilization. In observance of new information technologies that have become readily accessible to drivers and parking agencies, we develop a dynamic non-cooperative bi-level model (i.e. Stackelberg leader-follower game) to set parking prices in real-time for effective parking access and space utilization. The model is expected to fit into an integrated parking pricing and management system, where parking reservations and transactions are facilitated by sensing and informatics infrastructures, that ensures the availability of convenient spaces at equilibrium market prices. It is shown with numerical examples that the proposed dynamic parking pricing model has the potential to virtually eliminate vehicle circling for parking, which results in significant reduction in adverse socioeconomic externalities such as traffic congestion and emissions. "
no-150100683,arxiv.org/abs/1501.00683,4/1/15,Performance Analysis of Simultaneous Wireless Information and Power Transfer with Ambient RF Energy Harvesting,1,0,1," Performance Analysis of Simultaneous Wireless Information and Power Transfer with Ambient RF Energy Harvesting The advance in RF energy transfer and harvesting technique over the past decade has enabled wireless energy replenishment for electronic devices, which is deemed as a promising alternative to address the energy bottleneck of conventional battery-powered devices. In this paper, by using a stochastic geometry approach, we aim to analyze the performance of an RF-powered wireless sensor in a downlink simultaneous wireless information and power transfer SWIPT system with ambient RF transmitters. Specifically, we consider the point-to-point downlink SWIPT transmission from an access point to a wireless sensor in a network, where ambient RF transmitters are distributed as a Ginibre ?determinantal point process DPP, which becomes the Poisson point process when ? approaches zero. In the considered network, we focus on analyzing the performance of a sensor equipped with the power-splitting architecture. Under this architecture, we characterize the expected RF energy harvesting rate of the sensor. Moreover, we derive the upper bound of both power and transmission outage probabilities. Numerical results show that our upper bounds are accurate for different value of ?. "
no-14125512,arxiv.org/abs/1412.5512,4/1/15,Permutations of context-free and indexed languages,0,0,0," Permutations of context-free and indexed languages We consider the cyclic closure of a language, and its generalisation to the operators introduced by Brandst\ adt. We prove that the cyclic closure of an indexed language is indexed, and that if is a context-free language then is indexed. "
no-150100637,arxiv.org/abs/1501.00637,4/1/15,Should I break up with my girlfriend? Will I find another? Or: An Algorithm for the Forecasting of Romantic Options,0,0,0," Should I break up with my girlfriend? Will I find another? Or: An Algorithm for the Forecasting of Romantic Options The prospect of finding love may be scary but the prospect of committing to a relationship for the rest of your life is almost certainly scary. The secretary problem is a parallel to romantic decision making where an individual decides when to be satisfied with a selection choice in the face of uncertain future options. However, the secretary problem and its variations still do not provide a practical solution in a world where individual preference, goals, and societal context create a highly complex space of values that factor into decision making. In light of these complexities, we offer a general process that can determine the value of romantic options in a highly personal context. This algorithm is currently being developed into a service that will be available in 2015 for the general public. "
no-14111397,arxiv.org/abs/1411.1397,4/1/15,Strong parallel repetition for free entangled games  with any number of players,0,0,0," Strong parallel repetition for free entangled games, with any number of players We present a strong parallel repetition theorem for the entangled value of multi-player, one-round free games (games where the inputs come from a product distribution). Our result is the first parallel repetition theorem for entangled games involving more than two players. Furthermore, our theorem applies to games where the players are allowed to output (possibly entangled) quantum states as answers. More specifically, let be a player free game, with entangled value . We show that the entangled value of the fold repetition of , , is at most . In the traditional setting of players, our parallel repetition theorem is optimal in terms of its dependence on and . For an arbitrary number of players, our result is nearly optimal: for all , we exhibit a player free game and such that . Hence, exponent of the repeated game value cannot be improved beyond . Our parallel repetition theorem improves on the prior results of [Jain, et al. 2014] and [Chailloux, Scarpa 2014] in a number of ways: (1) our theorem applies to a larger class of games (arbitrary number of players, quantum outputs); (2) we demonstrate that strong parallel repetition holds for the entangled value of free games: i.e., the base of the repeated game value is , rather than ; and (3) there is no dependence of the repeated game value on the input and output alphabets of . In contrast, it is known that the repeated game value of classical free games must depend on the output size. Thus our results demonstrate a seperation between the behavior of entangled games and classical games. "
no-150100729,arxiv.org/abs/1501.00729,4/1/15,Two Globally Convergent Adaptive Speed Observers for Mechanical Systems,0,0,1," Two Globally Convergent Adaptive Speed Observers for Mechanical Systems A globally exponentially stable speed observer for mechanical systems was recently reported in the literature, under the assumptions of known (or no) Coulomb friction and no disturbances. In this note we propose and adaptive version of this observer, which is robust vis--a--vis constant disturbances. Moreover, we propose a new globally convergent speed observer that, besides rejecting the disturbances, estimates some unknown friction coefficients for a class of mechanical systems that contains several practical examples. "
no-13035965,arxiv.org/abs/1303.5965,5/1/15,A catalog of matchstick graphs,0,0,1," A catalog of matchstick graphs Classification of planar unit-distance graphs with up to 9 edges, by homeomorphism and isomorphism classes. With exactly nine edges, there are 633 nonisomorphic connected matchstick graphs, of which 196 are topologically distinct from each other. Increasing edges' number, their quantities rise more than exponentially, in a still unclear way. "
no-150100909,arxiv.org/abs/1501.00909,5/1/15,Adaptive Objectness for Object Tracking,0,1,0," Adaptive Objectness for Object Tracking Object tracking is a long standing problem in vision. While great efforts have been spent to improve tracking performance, a simple yet reliable prior knowledge is left unexploited: the target object in tracking must be an object other than non-object. The recently proposed and popularized objectness measure provides a natural way to model such prior in visual tracking. Thus motivated, in this paper we propose to adapt objectness for visual object tracking. Instead of directly applying an existing objectness measure that is generic and handles various objects and environments, we adapt it to be compatible to the specific tracking sequence and object. More specifically, we use the newly proposed BING objectness as the base, and then train an object-adaptive objectness for each tracking task. The training is implemented by using an adaptive support vector machine that integrates information from the specific tracking target into the BING measure. We emphasize that the benefit of the proposed adaptive objectness, named ADOBING, is generic. To show this, we combine ADOBING with seven top performed trackers in recent evaluations. We run the ADOBING-enhanced trackers with their base trackers on two popular benchmarks, the CVPR2013 benchmark (50 sequences) and the Princeton Tracking Benchmark (100 sequences). On both benchmarks, our methods not only consistently improve the base trackers, but also achieve the best known performances. Noting that the way we integrate objectness in visual tracking is generic and straightforward, we expect even more improvement by using tracker-specific objectness. "
no-150101042,arxiv.org/abs/1501.01042,5/1/15,Augur: a decentralized  open-source platform for prediction markets,0,0,0," Augur: a decentralized, open-source platform for prediction markets Augur is a trustless, decentralized platform for prediction markets. It is an extension of Bitcoin Core's source code which preserves as much of Bitcoin's proven code and security as possible. Each feature required for prediction markets is constructed from Bitcoin's input/output-style transactions. "
no-150100841,arxiv.org/abs/1501.00841,5/1/15,Chasing the Ghosts of Ibsen: A computational stylistic analysis of drama in translation,0,0,0," Chasing the Ghosts of Ibsen: A computational stylistic analysis of drama in translation Research into the stylistic properties of translations is an issue which has received some attention in computational stylistics. Previous work by Rybicki (2006) on the distinguishing of character idiolects in the work of Polish author Henryk Sienkiewicz and two corresponding English translations using Burrow's Delta method concluded that idiolectal differences could be observed in the source texts and this variation was preserved to a large degree in both translations. This study also found that the two translations were also highly distinguishable from one another. Burrows (2002) examined English translations of Juvenal also using the Delta method, results of this work suggest that some translators are more adept at concealing their own style when translating the works of another author whereas other authors tend to imprint their own style to a greater extent on the work they translate. Our work examines the writing of a single author, Norwegian playwright Henrik Ibsen, and these writings translated into both German and English from Norwegian, in an attempt to investigate the preservation of characterization, defined here as the distinctiveness of textual contributions of characters. "
no-150100943,arxiv.org/abs/1501.00943,5/1/15,Comparative Studies of Clustering Techniques for Real-Time Dynamic Model Reduction,0,0,0," Comparative Studies of Clustering Techniques for Real-Time Dynamic Model Reduction Dynamic model reduction in power systems is necessary for improving computational efficiency. Traditional model reduction using linearized models or offline analysis would not be adequate to capture power system dynamic behaviors, especially the new mix of intermittent generation and intelligent consumption makes the power system more dynamic and non-linear. Real-time dynamic model reduction emerges as an important need. This paper explores the use of clustering techniques to analyze real-time phasor measurements to determine generator groups and representative generators for dynamic model reduction. Two clustering techniques -- graph clustering and evolutionary clustering -- are studied in this paper. Various implementations of these techniques are compared and also compared with a previously developed Singular Value Decomposition SVD-based dynamic model reduction approach. Various methods exhibit different levels of accuracy when comparing the reduced model simulation against the original model. But some of them are consistently accurate. From this comparative perspective, this paper provides a good reference point for practical implementations. "
no-150100039,arxiv.org/abs/1501.00039,5/1/15,Design  Construction  and Use of a Single Board Computer Beowulf Cluster: Application of the Small-Footprint  Low-Cost  InSignal 5420 Octa Board,0,0,0," Design, Construction, and Use of a Single Board Computer Beowulf Cluster: Application of the Small-Footprint, Low-Cost, InSignal 5420 Octa Board In recent years development in the area of Single Board Computing has been advancing rapidly. At Wolters Kluwer's Corporate Legal Services Division a prototyping effort was undertaken to establish the utility of such devices for practical and general computing needs. This paper presents the background of this work, the design and construction of a 64 core 96 GHz cluster, and their possibility of yielding approximately 400 GFLOPs from a set of small footprint InSignal boards created for just over $2,300. Additionally this paper discusses the software environment on the cluster, the use of a standard Beowulf library and its operation, as well as other software application uses including Elastic Search and ownCloud. Finally, consideration will be given to the future use of such technologies in a business setting in order to introduce new Open Source technologies, reduce computing costs, and improve Time to Market. Index Terms: Single Board Computing, Raspberry Pi, InSignal Exynos 5420, Linaro Ubuntu Linux, High Performance Computing, Beowulf clustering, Open Source, MySQL, MongoDB, ownCloud, Computing Architectures, Parallel Computing, Cluster Computing "
no-13046937,arxiv.org/abs/1304.6937,5/1/15,Detecting squarefree numbers,0,0,1," Detecting squarefree numbers We present an algorithm, based on the explicit formula for functions and conditional on GRH, for proving that a given integer is squarefree with little or no knowledge of its factorization. We analyze the algorithm both theoretically and practically, and use it to prove that several RSA challenge numbers are not squarefull. "
no-13070067,arxiv.org/abs/1307.0067,5/1/15,Extrinsic Jensen-Shannon Divergence: Applications to Variable-Length Coding,1,0,1," Extrinsic Jensen-Shannon Divergence: Applications to Variable-Length Coding This paper considers the problem of variable-length coding over a discrete memoryless channel DMC with noiseless feedback. The paper provides a stochastic control view of the problem whose solution is analyzed via a newly proposed symmetrized divergence, termed extrinsic Jensen-Shannon EJS divergence. It is shown that strictly positive lower bounds on EJS divergence provide non-asymptotic upper bounds on the expected code length. The paper presents strictly positive lower bounds on EJS divergence, and hence non-asymptotic upper bounds on the expected code length, for the following two coding schemes: variable-length posterior matching and MaxEJS coding scheme which is based on a greedy maximization of the EJS divergence. As an asymptotic corollary of the main results, this paper also provides a rate-reliability test. Variable-length coding schemes that satisfy the condition(s) of the test for parameters and , are guaranteed to achieve rate and error exponent . The results are specialized for posterior matching and MaxEJS to obtain deterministic one-phase coding schemes achieving capacity and optimal error exponent. For the special case of symmetric binary-input channels, simpler deterministic schemes of optimal performance are proposed and analyzed. "
no-150100857,arxiv.org/abs/1501.00857,5/1/15,Fast forward feature selection for the nonlinear classification of hyperspectral images,0,1,0," Fast forward feature selection for the nonlinear classification of hyperspectral images A fast forward feature selection algorithm is presented in this paper. It is based on a Gaussian mixture model GMM classifier. GMM are used for classifying hyperspectral images. The algorithm selects iteratively spectral features that maximizes an estimation of the classification rate. The estimation is done using the k-fold cross validation. In order to perform fast in terms of computing time, an efficient implementation is proposed. First, the GMM can be updated when the estimation of the classification rate is computed, rather than re-estimate the full model. Secondly, using marginalization of the GMM, sub models can be directly obtained from the full model learned with all the spectral features. Experimental results for two real hyperspectral data sets show that the method performs very well in terms of classification accuracy and processing time. Furthermore, the extracted model contains very few spectral channels. "
no-14096644,arxiv.org/abs/1409.6644,5/1/15,FLiER: Practical Topology Error Correction Using Sparse PMUs,0,0,0," FLiER: Practical Topology Error Correction Using Sparse PMUs In this paper, we present a Fingerprint Linear Estimation Routine (FLiER) to identify topology errors in power networks using readings from sparsely-deployed phasor measurement units (PMUs). When a power line is removed from a network, or when a substation is reconfigured, the event leaves a unique voltage fingerprint of bus voltage changes that we can identify using only the portion of the network directly observed by the PMUs. The naive brute-force approach to identify a failed line from such voltage fingerprints, though simple and accurate, is slow. We derive an approximate algorithm based on a local linearization that is faster and only slightly less accurate. We present experimental results using the IEEE 57-bus, IEEE 118-bus, and Polish 1999-2000 winter peak networks. "
no-14047282,arxiv.org/abs/1404.7282,5/1/15,Formal Proofs for Nonlinear Optimization,0,0,1," Formal Proofs for Nonlinear Optimization We present a formally verified global optimization framework. Given a semialgebraic or transcendental function and a compact semialgebraic domain , we use the nonlinear maxplus template approximation algorithm to provide a certified lower bound of over . This method allows to bound in a modular way some of the constituents of by suprema of quadratic forms with a well chosen curvature. Thus, we reduce the initial goal to a hierarchy of semialgebraic optimization problems, solved by sums of squares relaxations. Our implementation tool interleaves semialgebraic approximations with sums of squares witnesses to form certificates. It is interfaced with Coq and thus benefits from the trusted arithmetic available inside the proof assistant. This feature is used to produce, from the certificates, both valid underestimators and lower bounds for each approximated constituent. The application range for such a tool is widespread; for instance Hales' proof of Kepler's conjecture yields thousands of multivariate transcendental inequalities. We illustrate the performance of our formal framework on some of these inequalities as well as on examples from the global optimization literature. "
no-150100825,arxiv.org/abs/1501.00825,5/1/15,Group $K$-Means,0,1,0," Group Means We study how to learn multiple dictionaries from a dataset, and approximate any data point by the sum of the codewords each chosen from the corresponding dictionary. Although theoretically low approximation errors can be achieved by the global solution, an effective solution has not been well studied in practice. To solve the problem, we propose a simple yet effective algorithm \textit{Group Means}. Specifically, we take each dictionary, or any two selected dictionaries, as a group of means cluster centers, and then deal with the approximation issue by minimizing the approximation errors. Besides, we propose a hierarchical initialization for such a non-convex problem. Experimental results well validate the effectiveness of the approach. "
no-150101073,arxiv.org/abs/1501.01073,5/1/15,Impact of the Temperature and Humidity Variations on Link Quality of xm1000 Mote Sensors,0,0,0," Impact of the Temperature and Humidity Variations on Link Quality of xm1000 Mote Sensors The core motivations of deploying a sensor network for a specific application come from the autonomy of sensors, their reduced size, and their capabilities for computing and communicating in a short range. However, many challenges for sensor networks still exist: minimizing energy consumption, and ensuring the performance of communication that may be affected by many parameters. The work described in this paper covers mainly the analysis of the impact of the temperature and humidity variations on link quality of XM1000 operating under TinyOS. Two-way ANOVA test has been applied and the obtained results show that both the temperature and humidity variations impact RSSI. "
no-150100834,arxiv.org/abs/1501.00834,5/1/15,Inverse Renormalization Group Transformation in Bayesian Image Segmentations,0,1,0," Inverse Renormalization Group Transformation in Bayesian Image Segmentations A new Bayesian image segmentation algorithm is proposed by combining a loopy belief propagation with an inverse real space renormalization group transformation to reduce the computational time. In results of our experiment, we observe that the proposed method can reduce the computational time to less than one-tenth of that taken by conventional Bayesian approaches. "
no-14065988,arxiv.org/abs/1406.5988,5/1/15,Large System Analysis of the Energy Consumption Distribution in Multi-User MIMO Systems with Mobility,1,0,1," Large System Analysis of the Energy Consumption Distribution in Multi-User MIMO Systems with Mobility In this work, we consider the downlink of a single-cell multi-user MIMO system in which the base station BS makes use of antennas to communicate with single-antenna user equipments (UEs). The UEs move around in the cell according to a random walk mobility model. We aim at determining the energy consumption distribution when different linear precoding techniques are used at the BS to guarantee target rates within a finite time interval . The analysis is conducted in the asymptotic regime where and grow large with fixed ratio under the assumption of perfect channel state information CSI. Both recent and standard results from large system analysis are used to provide concise formulae for the asymptotic transmit powers and beamforming vectors for all considered schemes. These results are eventually used to provide a deterministic approximation of the energy consumption and to study its fluctuations around this value in the form of a central limit theorem. Closed-form expressions for the asymptotic means and variances are given. Numerical results are used to validate the accuracy of the theoretical analysis and to make comparisons. We show how the results can be used to approximate the probability that a battery-powered BS runs out of energy and also to design the cell radius for minimizing the energy consumption per unit area. The imperfect CSI case is also briefly considered. "
no-150105917,arxiv.org/abs/1501.05917,5/1/15,On Generalized Rectangular Fuzzy Model for Assessment,0,0,0, On Generalized Rectangular Fuzzy Model for Assessment The article is dedicated to the analysis of the existing models for assessment based of the fuzzy logic centroid technique. A new Generalized Rectangular Model were developed. Some generalizations of the existing models are offered. 
no-150100994,arxiv.org/abs/1501.00994,5/1/15,Online Reputation and Polling Systems: Data Incest  Social Learning and Revealed Preferences,0,0,0," Online Reputation and Polling Systems: Data Incest, Social Learning and Revealed Preferences This paper considers online reputation and polling systems where individuals make recommendations based on their private observations and recommendations of friends. Such interaction of individuals and their social influence is modelled as social learning on a directed acyclic graph. Data incest (misinformation propagation) occurs due to unintentional re-use of identical actions in the for- mation of public belief in social learning; the information gathered by each agent is mistakenly considered to be independent. This results in overconfidence and bias in estimates of the state. Necessary and sufficient conditions are given on the structure of information exchange graph to mitigate data incest. Incest removal algorithms are presented. Experimental results on human subjects are presented to illustrate the effect of social influence and data incest on decision making. These experimental results indicate that social learning protocols require careful design to handle and mitigate data incest. The incest removal algorithms are illustrated in an expectation polling system where participants in a poll respond with a summary of their friends' beliefs. Finally, the principle of revealed preferences arising in micro-economics theory is used to parse Twitter datasets to determine if social sensors are utility maximizers and then determine their utility functions. "
no-150100894,arxiv.org/abs/1501.00894,5/1/15,On Sharing  Memoization  and Polynomial Time (Long Version),0,0,0," On Sharing, Memoization, and Polynomial Time (Long Version) We study how the adoption of an evaluation mechanism with sharing and memoization impacts the class of functions which can be computed in polynomial time. We first show how a natural cost model in which lookup for an already computed value has no cost is indeed invariant. As a corollary, we then prove that the most general notion of ramified recurrence is sound for polynomial time, this way settling an open problem in implicit computational complexity. "